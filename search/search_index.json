{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Saga Orchestration with Kafka Demonstration","text":""},{"location":"#context","title":"Context","text":"<p>Introduced in 1987 by Hector Garcaa-Molrna Kenneth Salem paper the Saga pattern helps to support a long running transaction that can be broken up to a collection of sub transactions which can be interleaved any way with other transactions.</p> <p>With microservice each transaction updates data within a single service, each subsequent steps may be triggered by previous completion. </p>"},{"location":"#demonstration-scope","title":"Demonstration scope","text":"<p>The Saga choreography implementation is based on a fictious fresh content shipping business process, to send fresh food to remote location using refrigerated container on vessels.</p> <p>The Choreography variant of the SAGA pattern, done with Kafka, involves strong decoupling between services, and each participant listens to facts from other services and acts on them independently. So each service will have at least one topic representing states on its own entity. In the figure below the saga is managed in the context of the order microservice in the business functions and the in event listener.</p> <p></p> <p>The figure above illustrates that each service uses its own Kafka topic to keep events about state changes for their own business entity (e.g. Order, Vessel, Reefer). </p> <p>To manage the saga the <code>Order service</code> needs to listen to all participants topics and correlates events using the order ID as key.</p> <p>The Order business entity in this service supports a simple state machine as defined below:</p> <p></p> <p>Each state transition should generate an event to the <code>orders</code> topic. It is imoportant to note that some state transitions are event driven, while other are commands driven.</p> <p>The happy path looks like in the following sequence diagram:</p> <p></p> <p>In this scenario, we have a long running transaction that spans across the Order microservice which creates the order and maintains the Order states, the Reefer manager microservice which tries to find an empty refrigerator container with enough capacity in the origin port to support the order, the Vessel microservice which tries to find a boat, at the expected time of departure, from the origin port to the destination port with enough capacity for the refrigerator containers.</p> <p>As you can see in the diagram above, the transaction does not finish until a reefer has been allocated and a vessel is assigned to the order and, as a result, the order stays in pending state until all the sub transactions have successfully finished.</p>"},{"location":"#code-repository","title":"Code repository","text":"<p>The implementation of the services are done with Quarkus and Microprofile Reactive Messaging.</p> <p>Each code repository structure is based on the domain-driven-design practices, the onion architecture, with clear separation between layers (app, domain, infrastructure) and keep the domain layer using the ubiquituous language of each domain: order, reefer, and vessel.</p> <pre><code>       \u2514\u2500\u2500 order\n           \u251c\u2500\u2500 app\n           \u2502\u00a0\u00a0 \u2514\u2500\u2500 OrderCommandApplication.java\n           \u251c\u2500\u2500 domain\n           \u2502\u00a0\u00a0 \u251c\u2500\u2500 Address.java\n           \u2502\u00a0\u00a0 \u251c\u2500\u2500 OrderService.java\n           \u2502\u00a0\u00a0 \u2514\u2500\u2500 ShippingOrder.java\n           \u2514\u2500\u2500 infra\n               \u251c\u2500\u2500 api\n               \u2502\u00a0\u00a0 \u251c\u2500\u2500 ShippingOrderResource.java\n               \u2502\u00a0\u00a0 \u2514\u2500\u2500 VersionResource.java\n               \u251c\u2500\u2500 events\n               \u2502\u00a0\u00a0 \u251c\u2500\u2500 EventBase.java\n               \u2502\u00a0\u00a0 \u251c\u2500\u2500 order\n               \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 OrderCreatedEvent.java\n               \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 OrderEvent.java\n               \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 OrderEventProducer.java\n               \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 OrderUpdatedEvent.java\n               \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 OrderVariablePayload.java\n               \u2502\u00a0\u00a0 \u251c\u2500\u2500 reefer\n               \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 ReeferAgent.java\n               \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 ReeferAllocated.java\n               \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 ReeferEvent.java\n               \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 ReeferEventDeserializer.java\n               \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 ReeferVariablePayload.java\n               \u2502\u00a0\u00a0 \u2514\u2500\u2500 vessel\n               \u2502\u00a0\u00a0     \u251c\u2500\u2500 VesselAgent.java\n               \u2502\u00a0\u00a0     \u251c\u2500\u2500 VesselAllocated.java\n               \u2502\u00a0\u00a0     \u251c\u2500\u2500 VesselEvent.java\n               \u2502\u00a0\u00a0     \u251c\u2500\u2500 VesselEventDeserializer.java\n               \u2502\u00a0\u00a0     \u2514\u2500\u2500 VesselVariablePayload.java\n               \u2514\u2500\u2500 repo\n                   \u251c\u2500\u2500 OrderRepository.java\n                   \u2514\u2500\u2500 OrderRepositoryMem.java\n</code></pre> <p>Events are defined in the infrastructure level, Entities as DTO visible in JAX-RS APIs. The OpenAPI document can be built from the API definition from the code, a bottom up approach.</p>"},{"location":"#compensation","title":"Compensation","text":"<p>The SAGA pattern comes with the tradeoff that a compensation process must also be implemented in the case that one, or multiple, of the sub transactions fails or does not complete so that the system rolls back to the initial state before the transaction began.</p> <p>In our specific case, a new order creation transaction can fail either because we can not find a refrigerator container to be allocated to the order or we can not find a boat to assigned to the order.</p> <p>Most likely a compensation may involve a human to continue the process, or more complex business rules based, inference engine to do the appropriate actions to handle the order onHold.</p>"},{"location":"#no-reefer","title":"No reefer","text":"<p>When a new order creation is requested by a customer but there is no refrigerator container to be allocated to such order, either because the container(s) do not have enough capacity or there is no container available in the origin port for such order, the compensation process for the order creation transaction is quite simple. The order microservice will not get an answer from the reefer manager, and after a certain time, it will trigger the compensation flow by sending a OrderUpdate with status onHold. The vessel service which may has responded positively before that, may roll back the order to vessel allocation relationship.</p>"},{"location":"#no-vessel","title":"No vessel","text":"<p>This case is the sysmetric of the other one. The actions flow remains as expected for the SAGA transaction until the Vessel microservice is not answering after a time period or answering negatively. As a result, the Order Command microservice will transition the order to <code>OnHold</code> and emit an OrderUpdateEvent to inform the saga participants. In this case, the Reefer manager is one of those interested party, as it will need to kick off the compensation task, which in this case is nothing more than de-allocate the container to the order to make it available for any other coming order.</p>"},{"location":"#demonstration","title":"Demonstration","text":"<p>In this repository, we have define a docker compose file that let us run the demonstration on our local computer. </p> <ol> <li> <p>Start the solution, and open 4 web browser page to see the API of each service:</p> <pre><code>docker-compose up -d\n./scripts/openApis.sh\n</code></pre> <p>The following containers are running:</p> <pre><code>IMAGE                                               PORTS                                                  NAMES\njbcodeforce/saga-reefer-ms                           8443/tcp, 0.0.0.0:8081-&gt;8080/tcp                       reeferms\njbcodeforce/saga-vessel-ms                           8443/tcp, 0.0.0.0:8082-&gt;8080/tcp                       vesselms\njbcodeforce/saga-order-ms                            0.0.0.0:8080-&gt;8080/tcp, 8443/tcp                       orderms\nobsidiandynamics/kafdrop                             0.0.0.0:9000-&gt;9000/tcp                                 kafdrop\nquay.io/strimzi/kafka:latest-kafka-3.4.1                                                                    saga-choreography-kafka-addTopics-1\nquay.io/strimzi/kafka:latest-kafka-3.4.1             0.0.0.0:9092-&gt;9092/tcp, 0.0.0.0:29092-&gt;9092/tcp        kafka\nquay.io/apicurio/apicurio-registry-mem:2.4.4.Final   8443/tcp, 8778/tcp, 9779/tcp, 0.0.0.0:8090-&gt;8080/tcp   apicurio\nquay.io/strimzi/kafka:latest-kafka-3.4.1             0.0.0.0:2181-&gt;2181/tcp                                 zookeeper\n</code></pre> </li> <li> <p>Send a good order and validate the events are created and the state of the order:</p> <pre><code>./e2e/sendGoodOrder.sh\n</code></pre> <p>The response will be:</p> <pre><code>{\"orderID\":\"efe301e5-8c25-4568-8cd3-c6f8655e301d\",\n\"productID\":\"P01\",\n\"customerID\":\"C01\",\n\"quantity\":10,\n\"pickupAddress\":{\"street\":\"1st main street\",\"city\":\"San Francisco\",\"country\":\"USA\",\"state\":\"CA\",\"zipcode\":\"95051\"},\n\"pickupDate\":\"2023/9/1\",\n\"destinationAddress\":{\"street\":\"1st horizon road\",\"city\":\"Hong Kong\",\"country\":\"HK\",\"state\":\"S1\",\"zipcode\":\"95051\"},\n\"expectedDeliveryDate\":null,\"\ncreationDate\":\"2023-09-19\",\n\"updateDate\":\"2023-09-19\",\n\"status\":\"pending\",\n\"vesselID\":null,\n\"containerIDs\":null}%  </code></pre> <p>We can use Kafdrop at [http://localhost:9000] to see the content of the different topics.</p> <p></p> <p>Then select a topic and go to the message view:</p> <p></p> <p>We can do the same for Reefers and Vessels topics.</p> </li> <li> <p>The status of the order is now \"Assigned\".</p> </li> <li> <p>Assess the compensation flow with one of the two order:</p> <pre><code>./e2e/sendNoReeferOrder.sh\n# or\n./e2e/sendNoVesselOrder.sh\n</code></pre> </li> </ol>"},{"location":"#more-reading","title":"More reading","text":"<ul> <li>Quarkus Apache Kafka user guide.</li> </ul>"},{"location":"CONTRIBUTING/","title":"CONTRIBUTING","text":""},{"location":"CONTRIBUTING/#contributing","title":"Contributing","text":"<p>Anyone can contribute to my assets. I welcome your collaboration &amp; contributions happily, as our reference applications are meant to reflect your real world scenarios. There are multiple ways to contribute: report bugs and improvement suggestions, improve documentation, and contribute code.</p>"},{"location":"CONTRIBUTING/#bug-reports-documentation-changes-and-feature-requests","title":"Bug reports, documentation changes, and feature requests","text":"<p>If you would like to contribute back to the project in the form of encountered bug reports, necessary documentation changes, or new feature requests, this can be done through the use of the repository's Issues list.  </p> <p>Before opening a new issue, please reference the existing list to make sure a similar or duplicate item does not already exist.  Otherwise, please be as explicit as possible when creating the new item and be sure to include the following:</p> <ul> <li>Bug reports</li> <li>Specific Project Version</li> <li>Deployment environment</li> <li>A minimal, but complete, setup of steps to recreate the problem</li> <li>Documentation changes</li> <li>URL to existing incorrect or incomplete documentation (either in the project's GitHub repo or external product documentation)</li> <li>Updates required to correct current inconsistency</li> <li>If possible, a link to a project fork, sample, or workflow to expose the gap in documentation.</li> <li>Feature requests</li> <li>Complete description of project feature request, including but not limited to, components of the existing project that are impacted, as well as additional components that may need to be created.</li> <li>A minimal, but complete, setup of steps to recreate environment necessary to identify the new feature's current gap.</li> </ul> <p>The more explicit and thorough you are in opening GitHub Issues, the more efficient your interaction with the maintainers will be.  When creating the GitHub Issue for your bug report, documentation change, or feature request, be sure to add as many relevant labels as necessary (that are defined for that specific project).  These will vary by project, but will be helpful to the maintainers in quickly triaging your new GitHub issues.</p>"},{"location":"CONTRIBUTING/#code-contributions","title":"Code contributions","text":"<p>We really value contributions, and to maximize the impact of code contributions, we request that any contributions follow the guidelines below.  If you are new to open source contribution and would like some more pointers or guidance, you may want to check out Your First PR and First Timers Only.  These are a few projects that help on-board new contributors to the overall process.</p>"},{"location":"CONTRIBUTING/#coding-and-pull-requests-best-practices","title":"Coding and Pull Requests best practices","text":"<ul> <li> <p>Please ensure you follow the coding standard and code formatting used throughout the existing code base.</p> </li> <li> <p>This may vary project by project, but any specific diversion from normal language standards will be explicitly noted.</p> </li> <li> <p>One feature / bug fix / documentation update per pull request</p> </li> <li> <p>Always pull the latest changes from upstream and rebase before creating any pull request.  </p> </li> <li>New pull requests should be created against the <code>integration</code> branch of the repository, if available.</li> <li> <p>This ensures new code is included in full-stack integration tests before being merged into the <code>master</code> branch</p> </li> <li> <p>All new features must be accompanied by associated tests.</p> </li> <li> <p>Make sure all tests pass locally before submitting a pull request.</p> </li> <li>Include tests with every feature enhancement, improve tests with every bug fix</li> </ul>"},{"location":"CONTRIBUTING/#github-and-git-flow","title":"Github and git flow","text":"<p>The internet is littered with guides and information on how to use and understand git.</p> <p>However, here's a compact guide that follows the suggested workflow</p> <p></p> <ol> <li> <p>Fork the desired repo in github.</p> </li> <li> <p>Clone your repo to your local computer.</p> </li> <li> <p>Add the upstream repository</p> <p>Note: Guide for step 1-3 here: forking a repo</p> </li> <li> <p>Create new development branch off the targeted upstream branch.  This will often be <code>main</code>.</p> <pre><code>git checkout -b &lt;my-feature-branch&gt; main\n</code></pre> </li> <li> <p>Do your work:</p> </li> <li> <p>Write your code</p> </li> <li>Write your tests</li> <li>Pass your tests locally</li> <li>Commit your intermediate changes as you go and as appropriate</li> <li> <p>Repeat until satisfied</p> </li> <li> <p>Fetch latest upstream changes (in case other changes had been delivered upstream while you were developing your new feature).</p> <pre><code>git fetch upstream\n</code></pre> </li> <li> <p>Rebase to the latest upstream changes, resolving any conflicts. This will 'replay' your local commits, one by one, after the changes delivered upstream while you were locally developing, letting you manually resolve any conflict.</p> <p><pre><code>git branch --set-upstream-to=upstream/master\ngit rebase\n</code></pre> Instructions on how to manually resolve a conflict and commit the new change or skip your local replayed commit will be presented on screen by the git CLI.</p> </li> <li> <p>Push the changes to your repository</p> <pre><code>git push origin &lt;my-feature-branch&gt;\n</code></pre> </li> <li> <p>Create a pull request against the same targeted upstream branch.</p> <p>Creating a pull request</p> </li> </ol> <p>Once the pull request has been reviewed, accepted and merged into the main github repository, you should synchronise your remote and local forked github repository <code>master</code> branch with the upstream master branch. To do so:</p> <ol> <li> <p>Pull to your local forked repository the latest changes upstream (that is, the pull request).</p> <pre><code>git pull upstream main\n</code></pre> </li> <li> <p>Push those latest upstream changes pulled locally to your remote forked repository.</p> <pre><code>git push origin main\n</code></pre> </li> </ol>"},{"location":"CONTRIBUTING/#what-happens-next","title":"What happens next?","text":"<ul> <li> <p>All pull requests will be automatically built and unit tested by travis-ci, when implemented by that specific project.</p> </li> <li> <p>You can determine if a given project is enabled for travis-ci unit tests by the existence of a <code>.travis.yml</code> file in the root of the repository or branch.</p> </li> <li> <p>When in use, all travis-ci unit tests must pass completely before any further review or discussion takes place.</p> </li> <li> <p>The repository maintainer will then inspect the commit and, if accepted, will pull the code into the upstream branch.</p> </li> <li>Should a maintainer or reviewer ask for changes to be made to the pull request, these can be made locally and pushed to your forked repository and branch.</li> <li>Commits passing this stage will make it into the next release cycle for the given project.</li> </ul>"}]}